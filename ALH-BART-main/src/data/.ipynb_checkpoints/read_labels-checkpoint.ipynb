{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_conversation(data, labels, sep = ' | '):\n",
    "    conversations = []\n",
    "    summaries = []\n",
    "    for i in range(0, len(data)):\n",
    "        if len(data[i]['dialogue'].split('\\r\\n')) > 1:\n",
    "            sentences = data[i]['dialogue'].replace(\"|\", \" \").split('\\r\\n')\n",
    "            \n",
    "        else:\n",
    "            sentences = data[i]['dialogue'].replace(\"|\", \" \").split('\\n')\n",
    "            \n",
    "        if len(sentences) == 1:\n",
    "            continue\n",
    "            \n",
    "    \n",
    "        summaries.append(data[i]['summary'].strip('\\n').replace('\\r\\nt', ' '))\n",
    "\n",
    "        if len(labels) > 1:\n",
    "            \n",
    "            temp = ''\n",
    "            #temp += sentences[0]\n",
    "            #for j in range(1, len(sentences)):\n",
    "            #    if labels[i][j] != labels[i][j-1]:\n",
    "            #        \n",
    "            #        temp = temp + sep + sentences[j]\n",
    "            #    else:\n",
    "            #        temp = temp + ' ' + sentences[j]\n",
    "            \n",
    "            #temp = ' | '\n",
    "            temp = ' | '\n",
    "            #temp = \" \"\n",
    "            temp += sentences[0]\n",
    "            for j in range(1, len(sentences)):\n",
    "                if labels[i][j] != labels[i][j-1]:\n",
    "                    \n",
    "                    temp = temp + sep + sentences[j]\n",
    "                else:\n",
    "                    temp = temp + ' ' + sentences[j]\n",
    "            #temp += ' | '\n",
    "            conversations.append(temp)\n",
    "        elif labels[0] == 1:\n",
    "            conversations.append(' <|> ' + ' <|> '.join(sentences))\n",
    "        elif labels[0] == 0:\n",
    "            conversations.append(' <|> ' + ' '.join(sentences))\n",
    "        \n",
    "    return conversations, summaries\n",
    "    \n",
    "\n",
    "def transform_format(prefix, label_type = '_bow_c99_label'):\n",
    "    with open(prefix + '.json', encoding = 'utf8') as json_file:\n",
    "        data = json.load(json_file)\n",
    "    if label_type != '_all' and label_type != '_none':\n",
    "        with open(prefix + label_type +'.pkl', 'rb') as f:\n",
    "            labels = pickle.load(f)\n",
    "    elif label_type == '_all':\n",
    "        labels = [1]\n",
    "    elif label_type == '_none':\n",
    "        labels = [0]\n",
    "        \n",
    "    cons, sums = concat_conversation(data, labels)\n",
    "    \n",
    "    print(len(cons))\n",
    "    print(len(sums))\n",
    "    \n",
    "\n",
    "    with open(prefix + label_type +'.source', 'wt', encoding='utf-8') as source_file, open(prefix + label_type + '.target', 'wt', encoding='utf-8') as target_file:\n",
    "        \n",
    "        for i in range(0, len(cons)):\n",
    "            #print(i)\n",
    "            article = cons[i]\n",
    "            abstract = sums[i]\n",
    "            #try:\n",
    "            source_file.write(article + '\\n')\n",
    "            target_file.write(abstract + '\\n')\n",
    "            #except:\n",
    "            #    print(article)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_conversation(data, labels, sep = ' <}> '):\n",
    "    conversations = []\n",
    "    summaries = []\n",
    "    for i in range(0, len(data)):\n",
    "        \n",
    "        if len(data[i]['dialogue'].split('\\r\\n')) > 1:\n",
    "            sentences = data[i]['dialogue'].split('\\r\\n')\n",
    "            \n",
    "        else:\n",
    "            sentences = data[i]['dialogue'].split('\\n')\n",
    "            \n",
    "        \n",
    "        \n",
    "        if len(sentences) == 1:\n",
    "            continue\n",
    "        \n",
    "        summaries.append(data[i]['summary'].strip('\\n').replace('\\r\\nt', ' '))\n",
    "\n",
    "        if len(labels) > 1:\n",
    "            \n",
    "            #temp = ''\n",
    "            #temp += sentences[0]\n",
    "            #for j in range(1, len(sentences)):\n",
    "            #    if labels[i][j] != labels[i][j-1]:\n",
    "            #        \n",
    "            #        temp = temp + sep + sentences[j]\n",
    "            #    else:\n",
    "            #        temp = temp + ' ' + sentences[j]\n",
    "            \n",
    "            temp = ''\n",
    "            temp += sentences[0]\n",
    "            flag = 0\n",
    "            for j in range(1, len(sentences)):\n",
    "                if labels[i][j] != labels[i][j-1]:\n",
    "                    flag = 1\n",
    "                    temp = temp + sep + sentences[j]\n",
    "                else:\n",
    "                    temp = temp + ' ' + sentences[j]\n",
    "            temp += ' <}>'\n",
    "            conversations.append(temp)\n",
    "            \n",
    "            if flag == 0:\n",
    "                pass\n",
    "                #print(i, temp)\n",
    "                #break\n",
    "        \n",
    "        elif labels[0] == 1:\n",
    "            conversations.append(' <}> '.join(sentences) + ' <}>')\n",
    "        elif labels[0] == 0:\n",
    "            conversations.append(' '.join(sentences) + ' <}>')\n",
    "        \n",
    "    return conversations, summaries\n",
    "    \n",
    "\n",
    "def transform_format(prefix, label_type = '_bow_c99_label'):\n",
    "    with open(prefix + '.json', encoding = 'utf8') as json_file:\n",
    "        data = json.load(json_file)\n",
    "    if label_type != '_all' and label_type != '_none':\n",
    "        with open(prefix + label_type +'.pkl', 'rb') as f:\n",
    "            labels = pickle.load(f)\n",
    "    elif label_type == '_all':\n",
    "        labels = [1]\n",
    "    elif label_type == '_none':\n",
    "        labels = [0]\n",
    "        \n",
    "    cons, sums = concat_conversation(data, labels)\n",
    "    \n",
    "    print(len(cons))\n",
    "    print(len(sums))\n",
    "    \n",
    "\n",
    "    with open(prefix + label_type +'.source', 'wt', encoding='utf-8') as source_file, open(prefix + label_type + '.target', 'wt', encoding='utf-8') as target_file:\n",
    "        \n",
    "        for i in range(0, len(cons)):\n",
    "            #print(i)\n",
    "            article = cons[i]\n",
    "            abstract = sums[i]\n",
    "            #try:\n",
    "            source_file.write(article + '\\n')\n",
    "            target_file.write(abstract + '\\n')\n",
    "            #except:\n",
    "            #    print(article)\n",
    "            \n",
    "    return cons\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_conversation(data, labels, sep = ' | '):\n",
    "    conversations = []\n",
    "    summaries = []\n",
    "    for i in range(0, len(data)):\n",
    "        if len(data[i]['dialogue'].split('\\r\\n')) > 1:\n",
    "            sentences = data[i]['dialogue'].replace(\" |\", \" \").split('\\r\\n')\n",
    "            \n",
    "        else:\n",
    "            sentences = data[i]['dialogue'].replace(\" |\", \" \").split('\\n')\n",
    "            \n",
    "        if len(sentences) == 1:\n",
    "            continue\n",
    "            \n",
    "    \n",
    "        summaries.append(data[i]['summary'].strip('\\n').replace('\\r\\nt', ' '))\n",
    "\n",
    "        if len(labels) > 1:\n",
    "            \n",
    "            temp = ''\n",
    "            #temp += sentences[0]\n",
    "            #for j in range(1, len(sentences)):\n",
    "            #    if labels[i][j] != labels[i][j-1]:\n",
    "            #        \n",
    "            #        temp = temp + sep + sentences[j]\n",
    "            #    else:\n",
    "            #        temp = temp + ' ' + sentences[j]\n",
    "            \n",
    "            #temp = ' | '\n",
    "            #temp = ' | '\n",
    "            #temp = \" \"\n",
    "            temp += sentences[0]\n",
    "            for j in range(1, len(sentences)):\n",
    "                if labels[i][j] != labels[i][j-1]:\n",
    "                    \n",
    "                    temp = temp + sep + sentences[j]\n",
    "                else:\n",
    "                    temp = temp + ' ' + sentences[j]\n",
    "            temp += ' | '\n",
    "            conversations.append(temp)\n",
    "        elif labels[0] == 1:\n",
    "            conversations.append(' | ' + ' | '.join(sentences))\n",
    "        elif labels[0] == 0:\n",
    "            conversations.append(' | ' + ' '.join(sentences))\n",
    "        \n",
    "    return conversations, summaries\n",
    "    \n",
    "\n",
    "def transform_format(prefix, label_type = '_bow_c99_label'):\n",
    "    with open(prefix + '.json', encoding = 'utf8') as json_file:\n",
    "        data = json.load(json_file)\n",
    "    if label_type != '_all' and label_type != '_none':\n",
    "        with open(prefix + label_type +'.pkl', 'rb') as f:\n",
    "            labels = pickle.load(f)\n",
    "    elif label_type == '_all':\n",
    "        labels = [1]\n",
    "    elif label_type == '_none':\n",
    "        labels = [0]\n",
    "        \n",
    "    cons, sums = concat_conversation(data, labels)\n",
    "    \n",
    "    print(len(cons))\n",
    "    print(len(sums))\n",
    "    \n",
    "\n",
    "    with open(prefix + label_type +'.source', 'wt', encoding='utf-8') as source_file, open(prefix + label_type + '.target', 'wt', encoding='utf-8') as target_file:\n",
    "        \n",
    "        for i in range(0, len(cons)):\n",
    "            #print(i)\n",
    "            article = cons[i]\n",
    "            abstract = sums[i]\n",
    "            #try:\n",
    "            source_file.write(article + '\\n')\n",
    "            target_file.write(abstract + '\\n')\n",
    "            #except:\n",
    "            #    print(article)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14731\n",
      "14731\n",
      "14731\n",
      "14731\n",
      "14731\n",
      "14731\n",
      "818\n",
      "818\n",
      "818\n",
      "818\n",
      "818\n",
      "818\n",
      "819\n",
      "819\n",
      "819\n",
      "819\n",
      "819\n",
      "819\n"
     ]
    }
   ],
   "source": [
    "for u in ['train', 'val', 'test']:\n",
    "    transform_format(u, '_all')\n",
    "    transform_format(u, '_none')\n",
    "    #transform_format(u, '_bow_c99_label')\n",
    "    #transform_format(u, '_word_c99_label')\n",
    "    #transform_format(u, '_bow_sent_label')\n",
    "    #transform_format(u, '_sent_trans_cons_label') # first\n",
    "    #transform_format(u, '_sent_c99_label') # back with a space in replace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Olivia: Who are you voting for in this election?  Oliver: Liberals as always. Olivia: Me too!! Oliver: Great\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "cons = transform_format('train', '_sent_c99_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train' + '_sent_c99_label' +'.pkl', 'rb') as f:\n",
    "    labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 2, 3, 3]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(cons)):\n",
    "    if len(cons[i]) < 30:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('Mark: hi | Dede: cant talk right now  Mark: :/ | ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "819"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train' + '.json', encoding = 'utf8') as json_file:\n",
    "        data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[6054]['dialogue'].replace(\" |\", \" \").split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[[3.0,3,3], [2,2,2], [4,2,5]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.transpose(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[3., 2., 4.],\n",
       "         [3., 2., 2.],\n",
       "         [3., 2., 5.]]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4.],\n",
       "         [3.],\n",
       "         [5.]]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.max_pool1d(b, kernel_size = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.tensor([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.eq(2) + a.eq(1) + a.eq(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
